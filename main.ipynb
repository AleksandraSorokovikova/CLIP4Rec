{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.train import *\n",
    "from src.processing import *\n",
    "from src.models import *\n",
    "from src.inference import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/teamspace/studios/this_studio/CLIP4Rec/src/processing.py:20: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  movies_metadata = pd.read_csv(movies_metadata_path)\n",
      "100%|██████████| 8846/8846 [00:00<00:00, 471536.04it/s]\n",
      "100%|██████████| 4012/4012 [00:04<00:00, 977.49it/s] \n",
      "100%|██████████| 2212/2212 [00:00<00:00, 452046.41it/s]\n"
     ]
    }
   ],
   "source": [
    "vocab = Vocabulary()\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "ratings_df, movie_descriptions, movies_metadata = create_ratings_df(\n",
    "    number_of_movies=7500,\n",
    "    frac=0.01,\n",
    "    links_path='CLIP4Rec/archive/links.csv',\n",
    "    movies_metadata_path='CLIP4Rec/archive/movies_metadata.csv',\n",
    "    ratings_path='CLIP4Rec/archive/ratings.csv'\n",
    "    )\n",
    "sequences = get_sequences(ratings_df)\n",
    "vocab.build_vocab(sequences)\n",
    "\n",
    "train_sentences, val_sentences = train_test_split(sequences, test_size=0.2, random_state=42)\n",
    "train_data, film_descriptions_encoded = prepare_dataset(\n",
    "    train_sentences, movie_descriptions, tokenizer, vocab, encode_descriptions=True\n",
    ")\n",
    "val_data = prepare_dataset(\n",
    "    val_sentences, movie_descriptions, tokenizer, vocab\n",
    ")\n",
    "\n",
    "train_dataset = FilmRecommendationDataset(train_data, film_descriptions_encoded)\n",
    "val_dataset = FilmRecommendationDataset(val_data, film_descriptions_encoded)\n",
    "\n",
    "epochs = 2\n",
    "batch_size = 24\n",
    "lr = 0.0001\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "film_encoder = SASFilmEncoder(item_num=len(vocab.word_to_index), seq_len=seq_len, embed_dim=384, device=device)\n",
    "text_encoder = TextEncoder(bert_model, output_dim=384)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 50/369 [00:30<03:12,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 50\n",
      "Accuracy: 0.0067\n",
      "Agreggated loss: 3.0922\n",
      "Classification loss: 8.2004\n",
      "Contrastive loss: 1.3959\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 100/369 [01:01<02:43,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 100\n",
      "Accuracy: 0.0083\n",
      "Agreggated loss: 3.0266\n",
      "Classification loss: 7.9687\n",
      "Contrastive loss: 1.3042\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 150/369 [01:31<02:13,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 150\n",
      "Accuracy: 0.0058\n",
      "Agreggated loss: 2.9864\n",
      "Classification loss: 7.8433\n",
      "Contrastive loss: 1.2462\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 200/369 [02:01<01:42,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 200\n",
      "Accuracy: 0.0092\n",
      "Agreggated loss: 2.9589\n",
      "Classification loss: 7.7503\n",
      "Contrastive loss: 1.2089\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 250/369 [02:32<01:12,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 250\n",
      "Accuracy: 0.0058\n",
      "Agreggated loss: 2.9383\n",
      "Classification loss: 7.6888\n",
      "Contrastive loss: 1.1794\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 300/369 [03:02<00:42,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 300\n",
      "Accuracy: 0.0033\n",
      "Agreggated loss: 2.9227\n",
      "Classification loss: 7.6505\n",
      "Contrastive loss: 1.1555\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 350/369 [03:33<00:11,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 350\n",
      "Accuracy: 0.0083\n",
      "Agreggated loss: 2.9112\n",
      "Classification loss: 7.6335\n",
      "Contrastive loss: 1.1351\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 369/369 [03:44<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 369\n",
      "Accuracy: 0.0022\n",
      "Agreggated loss: 2.9064\n",
      "Classification loss: 7.6210\n",
      "Contrastive loss: 1.1278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [00:19<00:00,  4.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Val Loss: 2.8091, Val Accuracy: 0.0059\n",
      "Val Classification loss: 7.4839\n",
      "Val Contrastive loss: 0.9580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 50/369 [00:30<03:14,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 50\n",
      "Accuracy: 0.0083\n",
      "Agreggated loss: 2.7671\n",
      "Classification loss: 7.0671\n",
      "Contrastive loss: 0.9740\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 100/369 [01:00<02:44,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 100\n",
      "Accuracy: 0.0050\n",
      "Agreggated loss: 2.7710\n",
      "Classification loss: 7.1230\n",
      "Contrastive loss: 0.9682\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 150/369 [01:31<02:13,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 150\n",
      "Accuracy: 0.0050\n",
      "Agreggated loss: 2.7686\n",
      "Classification loss: 7.1165\n",
      "Contrastive loss: 0.9649\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 200/369 [02:01<01:42,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 200\n",
      "Accuracy: 0.0117\n",
      "Agreggated loss: 2.7636\n",
      "Classification loss: 7.0959\n",
      "Contrastive loss: 0.9600\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 250/369 [02:32<01:12,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 250\n",
      "Accuracy: 0.0125\n",
      "Agreggated loss: 2.7603\n",
      "Classification loss: 7.0882\n",
      "Contrastive loss: 0.9556\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 300/369 [03:02<00:41,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 300\n",
      "Accuracy: 0.0042\n",
      "Agreggated loss: 2.7575\n",
      "Classification loss: 7.0796\n",
      "Contrastive loss: 0.9521\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 350/369 [03:33<00:11,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 350\n",
      "Accuracy: 0.0108\n",
      "Agreggated loss: 2.7564\n",
      "Classification loss: 7.0833\n",
      "Contrastive loss: 0.9490\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 369/369 [03:44<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 369\n",
      "Accuracy: 0.0067\n",
      "Agreggated loss: 2.7554\n",
      "Classification loss: 7.0799\n",
      "Contrastive loss: 0.9480\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [00:19<00:00,  4.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Val Loss: 2.7858, Val Accuracy: 0.0081\n",
      "Val Classification loss: 7.5476\n",
      "Val Contrastive loss: 0.8997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_clip(film_encoder, text_encoder, train_loader, val_loader, \n",
    "           epochs=epochs, lr=lr, device=device, iter_verbose=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(film_encoder.state_dict(), 'CLIP4Rec/artifacts/film_encoder_weights_test.pth')\n",
    "torch.save(text_encoder.state_dict(), 'CLIP4Rec/artifacts/text_encoder_weights_test.pth')\n",
    "\n",
    "torch.save(train_dataset, 'CLIP4Rec/artifacts/train_dataset.pt')\n",
    "torch.save(val_dataset, 'CLIP4Rec/artifacts/val_dataset.pt')\n",
    "\n",
    "with open('CLIP4Rec/artifacts/ratings_df.pickle', 'wb') as f:\n",
    "  pickle.dump(ratings_df, f)\n",
    "\n",
    "with open('CLIP4Rec/artifacts/movie_descriptions.pickle', 'wb') as f:\n",
    "  pickle.dump(movie_descriptions, f)\n",
    "\n",
    "with open('CLIP4Rec/artifacts/sequences.pickle', 'wb') as f:\n",
    "  pickle.dump(sequences, f)\n",
    "\n",
    "with open('CLIP4Rec/artifacts/vocab.pickle', 'wb') as f:\n",
    "  pickle.dump(vocab, f)\n",
    "\n",
    "with open('CLIP4Rec/artifacts/film_descriptions_encoded.pickle', 'wb') as f:\n",
    "  pickle.dump(film_descriptions_encoded, f)\n",
    "\n",
    "with open('CLIP4Rec/artifacts/movies_metadata.pickle', 'wb') as f:\n",
    "  pickle.dump(movies_metadata, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_movies = [\"Only Lovers Left Alive\",\n",
    "               \"The Twilight Saga: Eclipse\",\n",
    "               \"Me Before You\",\n",
    "               \"(500) Days of Summer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = pd.read_pickle('CLIP4Rec/artifacts/vocab.pickle')\n",
    "movies_metadata = pd.read_pickle('CLIP4Rec/artifacts/movies_metadata.pickle')\n",
    "film_descriptions_encoded = pd.read_pickle('CLIP4Rec/artifacts/film_descriptions_encoded.pickle')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "inference = Inference(\n",
    "    film_encoder_path = 'CLIP4Rec/artifacts/film_encoder_weights_test.pth',\n",
    "    text_encoder_path = 'CLIP4Rec/artifacts/text_encoder_weights_test.pth',\n",
    "    vocab=vocab,\n",
    "    dim=384,\n",
    "    movies_metadata=movies_metadata,\n",
    "    seq_len=seq_len,\n",
    "    device=device,\n",
    "    bert_model=bert_model,\n",
    "    bert_tokenizer=bert_tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference.build_annoy_model(film_descriptions_encoded, num_trees=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
